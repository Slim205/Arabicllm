{
  "config_general": {
    "lighteval_sha": "1bcde543f10ace8ab221df11e8989b527674a774",
    "num_fewshot_seeds": 1,
    "override_batch_size": 8,
    "max_samples": null,
    "job_id": "",
    "start_time": 95257.133669756,
    "end_time": 95468.679642267,
    "total_evaluation_time_secondes": "211.54597251099767",
    "model_name": "_gpfs_workdir_barkallasl_Evaluation_ift_full1_Meta-Llama-3-8B-Instruct",
    "model_sha": "",
    "model_dtype": "torch.float16",
    "model_size": "14.96 GB",
    "config": null
  },
  "results": {
    "lighteval|arc:easy|0": {
      "acc": 0.8303872053872053,
      "acc_stderr": 0.007700835074784077,
      "acc_norm": 0.8278619528619529,
      "acc_norm_stderr": 0.0077461444362726785
    },
    "lighteval|openbookqa|0": {
      "acc": 0.36,
      "acc_stderr": 0.021487751089720526,
      "acc_norm": 0.434,
      "acc_norm_stderr": 0.02218721580302901
    },
    "lighteval|piqa|0": {
      "acc": 0.7981501632208923,
      "acc_stderr": 0.009364873741341416,
      "acc_norm": 0.79379760609358,
      "acc_norm_stderr": 0.009439460331609518
    },
    "lighteval|toxigen|0": {
      "acc": 0.4340425531914894,
      "acc_stderr": 0.016174290832374864,
      "acc_norm": 0.4319148936170213,
      "acc_norm_stderr": 0.016164899004911828
    },
    "all": {
      "acc": 0.6056449804498968,
      "acc_stderr": 0.013681937684555221,
      "acc_norm": 0.6218936131431385,
      "acc_norm_stderr": 0.01388442989395576
    }
  },
  "versions": {
    "lighteval|arc:easy|0": 0,
    "lighteval|openbookqa|0": 0,
    "lighteval|piqa|0": 0,
    "lighteval|toxigen|0": 0
  },
  "config_tasks": {
    "lighteval|arc:easy": {
      "name": "arc:easy",
      "prompt_function": "arc",
      "hf_repo": "ai2_arc",
      "hf_subset": "ARC-Easy",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm_nospace"
      ],
      "hf_avail_splits": [
        "train",
        "validation",
        "test"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": null,
      "few_shots_select": "random_sampling_from_train",
      "generation_size": 1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval",
        "arc"
      ],
      "original_num_docs": 2376,
      "effective_num_docs": 2376,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "lighteval|openbookqa": {
      "name": "openbookqa",
      "prompt_function": "openbookqa",
      "hf_repo": "openbookqa",
      "hf_subset": "main",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm_nospace"
      ],
      "hf_avail_splits": [
        "train",
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": null,
      "few_shots_select": null,
      "generation_size": -1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval"
      ],
      "original_num_docs": 500,
      "effective_num_docs": 500,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "lighteval|piqa": {
      "name": "piqa",
      "prompt_function": "piqa_harness",
      "hf_repo": "piqa",
      "hf_subset": "plain_text",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm_nospace"
      ],
      "hf_avail_splits": [
        "train",
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "validation"
      ],
      "few_shots_split": null,
      "few_shots_select": null,
      "generation_size": -1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval"
      ],
      "original_num_docs": 1838,
      "effective_num_docs": 1838,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "lighteval|toxigen": {
      "name": "toxigen",
      "prompt_function": "toxigen",
      "hf_repo": "skg/toxigen-data",
      "hf_subset": "annotated",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "train",
        "test"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": null,
      "few_shots_select": null,
      "generation_size": -1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval"
      ],
      "original_num_docs": 940,
      "effective_num_docs": 940,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    }
  },
  "summary_tasks": {
    "lighteval|arc:easy|0": {
      "hashes": {
        "hash_examples": "63703c3cdff55bec",
        "hash_full_prompts": "63703c3cdff55bec",
        "hash_input_tokens": "ea28fb94d3a4adc7",
        "hash_cont_tokens": "bc10d7bf63ff180c"
      },
      "truncated": 0,
      "non_truncated": 2376,
      "padded": 9221,
      "non_padded": 280,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "lighteval|openbookqa|0": {
      "hashes": {
        "hash_examples": "7bc6716005dd3312",
        "hash_full_prompts": "7bc6716005dd3312",
        "hash_input_tokens": "5b7079beee5d37c7",
        "hash_cont_tokens": "7cac5e00e5ead5ef"
      },
      "truncated": 0,
      "non_truncated": 500,
      "padded": 1917,
      "non_padded": 83,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "lighteval|piqa|0": {
      "hashes": {
        "hash_examples": "f7e288a8894cd149",
        "hash_full_prompts": "f7e288a8894cd149",
        "hash_input_tokens": "c41bd843919be633",
        "hash_cont_tokens": "7f940a4ab0ecaa70"
      },
      "truncated": 0,
      "non_truncated": 1838,
      "padded": 3445,
      "non_padded": 231,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "lighteval|toxigen|0": {
      "hashes": {
        "hash_examples": "bf31d64b3a76cfea",
        "hash_full_prompts": "bf31d64b3a76cfea",
        "hash_input_tokens": "9bc5b00a777bfa2b",
        "hash_cont_tokens": "b6ca678fafe4a5fd"
      },
      "truncated": 0,
      "non_truncated": 940,
      "padded": 1797,
      "non_padded": 83,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "ffe87f89c59f414c",
      "hash_full_prompts": "ffe87f89c59f414c",
      "hash_input_tokens": "c30dbb1aa2a16c04",
      "hash_cont_tokens": "bc3eb00bffc87df7"
    },
    "truncated": 0,
    "non_truncated": 5654,
    "padded": 16380,
    "non_padded": 677,
    "num_truncated_few_shots": 0
  }
}