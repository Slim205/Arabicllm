{
  "config_general": {
    "lighteval_sha": "1bcde543f10ace8ab221df11e8989b527674a774",
    "num_fewshot_seeds": 1,
    "override_batch_size": 8,
    "max_samples": null,
    "job_id": "",
    "start_time": 81880.469569535,
    "end_time": 82129.977768923,
    "total_evaluation_time_secondes": "249.50819938800123",
    "model_name": "meta-llama/Meta-Llama-3-8B-Instruct",
    "model_sha": "e1945c40cd546c78e41f1151f4db032b271faeaa",
    "model_dtype": "torch.bfloat16",
    "model_size": "14.96 GB",
    "config": null
  },
  "results": {
    "lighteval|arc:easy|0": {
      "acc": 0.8240740740740741,
      "acc_stderr": 0.00781297152212192,
      "acc_norm": 0.7870370370370371,
      "acc_norm_stderr": 0.008400745314528831
    },
    "lighteval|openbookqa|0": {
      "acc": 0.354,
      "acc_stderr": 0.021407582047916447,
      "acc_norm": 0.428,
      "acc_norm_stderr": 0.022149790663861926
    },
    "lighteval|piqa|0": {
      "acc": 0.7780195865070729,
      "acc_stderr": 0.009696120744662013,
      "acc_norm": 0.7872687704026116,
      "acc_norm_stderr": 0.00954822312304735
    },
    "lighteval|toxigen|0": {
      "acc": 0.4574468085106383,
      "acc_stderr": 0.01625768355724684,
      "acc_norm": 0.4319148936170213,
      "acc_norm_stderr": 0.016164899004911828
    },
    "all": {
      "acc": 0.6033851172729463,
      "acc_stderr": 0.013793589467986806,
      "acc_norm": 0.6085551752641675,
      "acc_norm_stderr": 0.014065914526587484
    }
  },
  "versions": {
    "lighteval|arc:easy|0": 0,
    "lighteval|openbookqa|0": 0,
    "lighteval|piqa|0": 0,
    "lighteval|toxigen|0": 0
  },
  "config_tasks": {
    "lighteval|arc:easy": {
      "name": "arc:easy",
      "prompt_function": "arc",
      "hf_repo": "ai2_arc",
      "hf_subset": "ARC-Easy",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm_nospace"
      ],
      "hf_avail_splits": [
        "train",
        "validation",
        "test"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": null,
      "few_shots_select": "random_sampling_from_train",
      "generation_size": 1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval",
        "arc"
      ],
      "original_num_docs": 2376,
      "effective_num_docs": 2376,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "lighteval|openbookqa": {
      "name": "openbookqa",
      "prompt_function": "openbookqa",
      "hf_repo": "openbookqa",
      "hf_subset": "main",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm_nospace"
      ],
      "hf_avail_splits": [
        "train",
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": null,
      "few_shots_select": null,
      "generation_size": -1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval"
      ],
      "original_num_docs": 500,
      "effective_num_docs": 500,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "lighteval|piqa": {
      "name": "piqa",
      "prompt_function": "piqa_harness",
      "hf_repo": "piqa",
      "hf_subset": "plain_text",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm_nospace"
      ],
      "hf_avail_splits": [
        "train",
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "validation"
      ],
      "few_shots_split": null,
      "few_shots_select": null,
      "generation_size": -1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval"
      ],
      "original_num_docs": 1838,
      "effective_num_docs": 1838,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "lighteval|toxigen": {
      "name": "toxigen",
      "prompt_function": "toxigen",
      "hf_repo": "skg/toxigen-data",
      "hf_subset": "annotated",
      "metric": [
        "loglikelihood_acc",
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "train",
        "test"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": null,
      "few_shots_select": null,
      "generation_size": -1,
      "stop_sequence": [
        "\n"
      ],
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "lighteval"
      ],
      "original_num_docs": 940,
      "effective_num_docs": 940,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    }
  },
  "summary_tasks": {
    "lighteval|arc:easy|0": {
      "hashes": {
        "hash_examples": "63703c3cdff55bec",
        "hash_full_prompts": "63703c3cdff55bec",
        "hash_input_tokens": "ea28fb94d3a4adc7",
        "hash_cont_tokens": "bc10d7bf63ff180c"
      },
      "truncated": 0,
      "non_truncated": 2376,
      "padded": 9221,
      "non_padded": 280,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "lighteval|openbookqa|0": {
      "hashes": {
        "hash_examples": "7bc6716005dd3312",
        "hash_full_prompts": "7bc6716005dd3312",
        "hash_input_tokens": "5b7079beee5d37c7",
        "hash_cont_tokens": "7cac5e00e5ead5ef"
      },
      "truncated": 0,
      "non_truncated": 500,
      "padded": 1917,
      "non_padded": 83,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "lighteval|piqa|0": {
      "hashes": {
        "hash_examples": "f7e288a8894cd149",
        "hash_full_prompts": "f7e288a8894cd149",
        "hash_input_tokens": "c41bd843919be633",
        "hash_cont_tokens": "7f940a4ab0ecaa70"
      },
      "truncated": 0,
      "non_truncated": 1838,
      "padded": 3445,
      "non_padded": 231,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "lighteval|toxigen|0": {
      "hashes": {
        "hash_examples": "bf31d64b3a76cfea",
        "hash_full_prompts": "bf31d64b3a76cfea",
        "hash_input_tokens": "9bc5b00a777bfa2b",
        "hash_cont_tokens": "b6ca678fafe4a5fd"
      },
      "truncated": 0,
      "non_truncated": 940,
      "padded": 1797,
      "non_padded": 83,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "ffe87f89c59f414c",
      "hash_full_prompts": "ffe87f89c59f414c",
      "hash_input_tokens": "c30dbb1aa2a16c04",
      "hash_cont_tokens": "bc3eb00bffc87df7"
    },
    "truncated": 0,
    "non_truncated": 5654,
    "padded": 16380,
    "non_padded": 677,
    "num_truncated_few_shots": 0
  }
}