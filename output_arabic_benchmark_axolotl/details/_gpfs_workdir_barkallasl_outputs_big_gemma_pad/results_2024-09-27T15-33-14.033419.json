{
  "config_general": {
    "lighteval_sha": "76aac4b0335f18606fb7f869b1419c1f6ab79aa1",
    "num_fewshot_seeds": 1,
    "override_batch_size": 2,
    "max_samples": null,
    "job_id": "",
    "start_time": 869.155998766,
    "end_time": 1432.547350962,
    "total_evaluation_time_secondes": "563.3913521960001",
    "model_name": "_gpfs_workdir_barkallasl_outputs_big_gemma_pad",
    "model_sha": "",
    "model_dtype": "torch.bfloat16",
    "model_size": "18.02 GB",
    "config": null
  },
  "results": {
    "community|arc_challenge_okapi_ar|0": {
      "acc_norm": 0.5887931034482758,
      "acc_norm_stderr": 0.01445339374807693
    },
    "community|arc_easy_ar|0": {
      "acc_norm": 0.5964467005076142,
      "acc_norm_stderr": 0.01009263136007106
    },
    "community|copa_ext_ar|0": {
      "acc_norm": 0.6222222222222222,
      "acc_norm_stderr": 0.051392052067171366
    },
    "community|openbook_qa_ext_ar|0": {
      "acc_norm": 0.5616161616161616,
      "acc_norm_stderr": 0.022324595132484144
    },
    "community|piqa_ar|0": {
      "acc_norm": 0.7195853791598472,
      "acc_norm_stderr": 0.010494910943365958
    },
    "community|sciq_ar|0": {
      "acc_norm": 0.5035175879396985,
      "acc_norm_stderr": 0.015858644526325832
    },
    "community|toxigen_ar|0": {
      "acc_norm": 0.8545454545454545,
      "acc_norm_stderr": 0.011536067667924128
    },
    "all": {
      "acc_norm": 0.6352466584913249,
      "acc_norm_stderr": 0.019450327920774203
    }
  },
  "versions": {
    "community|arc_challenge_okapi_ar|0": 0,
    "community|arc_easy_ar|0": 0,
    "community|copa_ext_ar|0": 0,
    "community|openbook_qa_ext_ar|0": 0,
    "community|piqa_ar|0": 0,
    "community|sciq_ar|0": 0,
    "community|toxigen_ar|0": 0
  },
  "config_tasks": {
    "community|arc_challenge_okapi_ar": {
      "name": "arc_challenge_okapi_ar",
      "prompt_function": "alghafa_prompt",
      "hf_repo": "OALL/AlGhafa-Arabic-LLM-Benchmark-Translated",
      "hf_subset": "arc_challenge_okapi_ar",
      "metric": [
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "validation",
      "few_shots_select": "sequential",
      "generation_size": null,
      "stop_sequence": null,
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "community"
      ],
      "original_num_docs": 1160,
      "effective_num_docs": 1160,
      "trust_dataset": null,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "community|arc_easy_ar": {
      "name": "arc_easy_ar",
      "prompt_function": "alghafa_prompt",
      "hf_repo": "OALL/AlGhafa-Arabic-LLM-Benchmark-Translated",
      "hf_subset": "arc_easy_ar",
      "metric": [
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "validation",
      "few_shots_select": "sequential",
      "generation_size": null,
      "stop_sequence": null,
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "community"
      ],
      "original_num_docs": 2364,
      "effective_num_docs": 2364,
      "trust_dataset": null,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "community|copa_ext_ar": {
      "name": "copa_ext_ar",
      "prompt_function": "copa_prompt_arabic",
      "hf_repo": "OALL/AlGhafa-Arabic-LLM-Benchmark-Translated",
      "hf_subset": "copa_ext_ar",
      "metric": [
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "validation",
      "few_shots_select": "sequential",
      "generation_size": null,
      "stop_sequence": null,
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "community"
      ],
      "original_num_docs": 90,
      "effective_num_docs": 90,
      "trust_dataset": null,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "community|openbook_qa_ext_ar": {
      "name": "openbook_qa_ext_ar",
      "prompt_function": "alghafa_prompt",
      "hf_repo": "OALL/AlGhafa-Arabic-LLM-Benchmark-Translated",
      "hf_subset": "openbook_qa_ext_ar",
      "metric": [
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "validation",
      "few_shots_select": "sequential",
      "generation_size": null,
      "stop_sequence": null,
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "community"
      ],
      "original_num_docs": 495,
      "effective_num_docs": 495,
      "trust_dataset": null,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "community|piqa_ar": {
      "name": "piqa_ar",
      "prompt_function": "alghafa_prompt",
      "hf_repo": "OALL/AlGhafa-Arabic-LLM-Benchmark-Translated",
      "hf_subset": "piqa_ar",
      "metric": [
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "validation",
      "few_shots_select": "sequential",
      "generation_size": null,
      "stop_sequence": null,
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "community"
      ],
      "original_num_docs": 1833,
      "effective_num_docs": 1833,
      "trust_dataset": null,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "community|sciq_ar": {
      "name": "sciq_ar",
      "prompt_function": "sciq_prompt_arabic",
      "hf_repo": "OALL/AlGhafa-Arabic-LLM-Benchmark-Translated",
      "hf_subset": "sciq_ar",
      "metric": [
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "validation",
      "few_shots_select": "sequential",
      "generation_size": null,
      "stop_sequence": null,
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "community"
      ],
      "original_num_docs": 995,
      "effective_num_docs": 995,
      "trust_dataset": null,
      "must_remove_duplicate_docs": null,
      "version": 0
    },
    "community|toxigen_ar": {
      "name": "toxigen_ar",
      "prompt_function": "toxigen_prompt_arabic",
      "hf_repo": "OALL/AlGhafa-Arabic-LLM-Benchmark-Translated",
      "hf_subset": "toxigen_ar",
      "metric": [
        "loglikelihood_acc_norm"
      ],
      "hf_avail_splits": [
        "test",
        "validation"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "validation",
      "few_shots_select": "sequential",
      "generation_size": null,
      "stop_sequence": null,
      "output_regex": null,
      "num_samples": null,
      "frozen": false,
      "suite": [
        "community"
      ],
      "original_num_docs": 935,
      "effective_num_docs": 935,
      "trust_dataset": null,
      "must_remove_duplicate_docs": null,
      "version": 0
    }
  },
  "summary_tasks": {
    "community|arc_challenge_okapi_ar|0": {
      "hashes": {
        "hash_examples": "ab893807673bc355",
        "hash_full_prompts": "ab893807673bc355",
        "hash_input_tokens": "ff00520b6e9cafc8",
        "hash_cont_tokens": "97747ced9f2d8add"
      },
      "truncated": 0,
      "non_truncated": 1160,
      "padded": 4640,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "community|arc_easy_ar|0": {
      "hashes": {
        "hash_examples": "acb688624acc3d04",
        "hash_full_prompts": "acb688624acc3d04",
        "hash_input_tokens": "707986477eeffbab",
        "hash_cont_tokens": "c26cb9f5a59e6209"
      },
      "truncated": 0,
      "non_truncated": 2364,
      "padded": 9347,
      "non_padded": 109,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "community|copa_ext_ar|0": {
      "hashes": {
        "hash_examples": "9bb83301bb72eecf",
        "hash_full_prompts": "9bb83301bb72eecf",
        "hash_input_tokens": "e40ce82d7f11ef05",
        "hash_cont_tokens": "ee82a813fea23641"
      },
      "truncated": 0,
      "non_truncated": 90,
      "padded": 180,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "community|openbook_qa_ext_ar|0": {
      "hashes": {
        "hash_examples": "923d41eb0aca93eb",
        "hash_full_prompts": "923d41eb0aca93eb",
        "hash_input_tokens": "a377af773e1df3c4",
        "hash_cont_tokens": "ce191efb415a2f2e"
      },
      "truncated": 0,
      "non_truncated": 495,
      "padded": 1969,
      "non_padded": 11,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "community|piqa_ar|0": {
      "hashes": {
        "hash_examples": "94bc205a520d3ea0",
        "hash_full_prompts": "94bc205a520d3ea0",
        "hash_input_tokens": "0296521c18e83623",
        "hash_cont_tokens": "a3dcf8cff5401143"
      },
      "truncated": 0,
      "non_truncated": 1833,
      "padded": 3600,
      "non_padded": 66,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "community|sciq_ar|0": {
      "hashes": {
        "hash_examples": "44d5639935c64eaa",
        "hash_full_prompts": "44d5639935c64eaa",
        "hash_input_tokens": "f4ea8dbd46664a9a",
        "hash_cont_tokens": "8c44378e6562e6e9"
      },
      "truncated": 0,
      "non_truncated": 995,
      "padded": 3928,
      "non_padded": 52,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "community|toxigen_ar|0": {
      "hashes": {
        "hash_examples": "1e139513004a9a2e",
        "hash_full_prompts": "1e139513004a9a2e",
        "hash_input_tokens": "6a695d13a87e22fb",
        "hash_cont_tokens": "ab45f1f7a24d1319"
      },
      "truncated": 0,
      "non_truncated": 935,
      "padded": 1835,
      "non_padded": 35,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "0908126260e93678",
      "hash_full_prompts": "0908126260e93678",
      "hash_input_tokens": "c4414903e7fed1e9",
      "hash_cont_tokens": "d9da4a0f5a023896"
    },
    "truncated": 0,
    "non_truncated": 7872,
    "padded": 25499,
    "non_padded": 273,
    "num_truncated_few_shots": 0
  }
}